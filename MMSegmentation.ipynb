{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Maramattia/Diabetic-Foot-Ulcer-Challenge/blob/main/MMSegmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QS8YHrEhbpas"
      },
      "source": [
        "## Install MMSegmentation\n",
        "This step may take several minutes. \n",
        "\n",
        "We use PyTorch 1.10 and CUDA 11.1 for this tutorial. You may install other versions by change the version number in pip install command. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWyLrLYaNEaL",
        "outputId": "665c429f-59a5-4d57-ed74-36960d20fc0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "Built on Mon_Oct_12_20:09:46_PDT_2020\n",
            "Cuda compilation tools, release 11.1, V11.1.105\n",
            "Build cuda_11.1.TC455_06.29190527_0\n",
            "gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
            "Copyright (C) 2017 Free Software Foundation, Inc.\n",
            "This is free software; see the source for copying conditions.  There is NO\n",
            "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Check nvcc version\n",
        "!nvcc -V\n",
        "# Check GCC version\n",
        "!gcc --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ki3WUBjKbutg",
        "outputId": "36e8357b-b01a-4391-9841-089daf9cf890"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/, https://download.pytorch.org/whl/cu113\n",
            "Requirement already satisfied: torch==1.12.0 in /usr/local/lib/python3.7/dist-packages (1.12.0+cu113)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.13.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.12.0) (4.1.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.21.6)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2022.6.15)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openmim\n",
            "  Downloading openmim-0.2.0-py2.py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 3.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pip>=19.3 in /usr/local/lib/python3.7/dist-packages (from openmim) (21.1.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from openmim) (1.3.5)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.5-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: Click in /usr/local/lib/python3.7/dist-packages (from openmim) (7.1.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from openmim) (0.8.10)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from openmim) (2.23.0)\n",
            "Collecting rich\n",
            "  Downloading rich-12.5.1-py3-none-any.whl (235 kB)\n",
            "\u001b[K     |████████████████████████████████| 235 kB 15.8 MB/s \n",
            "\u001b[?25hCollecting model-index\n",
            "  Downloading model_index-0.1.11-py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.7/dist-packages (from model-index->openmim) (3.4.1)\n",
            "Collecting ordered-set\n",
            "  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from model-index->openmim) (3.13)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown->model-index->openmim) (4.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown->model-index->openmim) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown->model-index->openmim) (3.8.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->openmim) (2022.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas->openmim) (1.21.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->openmim) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->openmim) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->openmim) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->openmim) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->openmim) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->openmim) (2.10)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from rich->openmim) (2.6.1)\n",
            "Collecting commonmark<0.10.0,>=0.9.0\n",
            "  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 6.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: ordered-set, commonmark, rich, model-index, colorama, openmim\n",
            "Successfully installed colorama-0.4.5 commonmark-0.9.1 model-index-0.1.11 openmim-0.2.0 ordered-set-4.1.0 rich-12.5.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://download.openmmlab.com/mmcv/dist/cu113/torch1.12.0/index.html\n",
            "Collecting mmcv-full==1.6.0\n",
            "  Downloading https://download.openmmlab.com/mmcv/dist/cu113/torch1.12.0/mmcv_full-1.6.0-cp37-cp37m-manylinux1_x86_64.whl (40.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 40.1 MB 2.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mmcv-full==1.6.0) (1.21.6)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from mmcv-full==1.6.0) (3.13)\n",
            "Requirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.7/dist-packages (from mmcv-full==1.6.0) (4.6.0.66)\n",
            "Collecting addict\n",
            "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Collecting yapf\n",
            "  Downloading yapf-0.32.0-py2.py3-none-any.whl (190 kB)\n",
            "\u001b[K     |████████████████████████████████| 190 kB 6.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from mmcv-full==1.6.0) (7.1.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from mmcv-full==1.6.0) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->mmcv-full==1.6.0) (3.0.9)\n",
            "Installing collected packages: yapf, addict, mmcv-full\n",
            "Successfully installed addict-2.4.0 mmcv-full-1.6.0 yapf-0.32.0\n"
          ]
        }
      ],
      "source": [
        "# Install PyTorch\n",
        "!pip install torch==1.12.0 torchvision --extra-index-url https://download.pytorch.org/whl/cu113\n",
        "# Install MMCV\n",
        "!pip install openmim\n",
        "!mim install mmcv-full==1.6.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nR-hHRvbNJJZ",
        "outputId": "ae8dbef5-725c-45f0-f342-62e6f1c25da1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'mmsegmentation'...\n",
            "remote: Enumerating objects: 10191, done.\u001b[K\n",
            "remote: Counting objects: 100% (70/70), done.\u001b[K\n",
            "remote: Compressing objects: 100% (59/59), done.\u001b[K\n",
            "remote: Total 10191 (delta 16), reused 48 (delta 11), pack-reused 10121\u001b[K\n",
            "Receiving objects: 100% (10191/10191), 14.46 MiB | 23.80 MiB/s, done.\n",
            "Resolving deltas: 100% (7445/7445), done.\n",
            "/content/mmsegmentation\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Obtaining file:///content/mmsegmentation\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mmsegmentation==0.27.0) (3.2.2)\n",
            "Collecting mmcls>=0.20.1\n",
            "  Downloading mmcls-0.23.2-py2.py3-none-any.whl (578 kB)\n",
            "\u001b[K     |████████████████████████████████| 578 kB 5.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mmsegmentation==0.27.0) (1.21.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from mmsegmentation==0.27.0) (21.3)\n",
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.7/dist-packages (from mmsegmentation==0.27.0) (3.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmsegmentation==0.27.0) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmsegmentation==0.27.0) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmsegmentation==0.27.0) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmsegmentation==0.27.0) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->mmsegmentation==0.27.0) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->mmsegmentation==0.27.0) (1.15.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from prettytable->mmsegmentation==0.27.0) (4.12.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prettytable->mmsegmentation==0.27.0) (0.2.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->prettytable->mmsegmentation==0.27.0) (3.8.1)\n",
            "Installing collected packages: mmcls, mmsegmentation\n",
            "  Running setup.py develop for mmsegmentation\n",
            "Successfully installed mmcls-0.23.2 mmsegmentation-0.27.0\n"
          ]
        }
      ],
      "source": [
        "!rm -rf mmsegmentation\n",
        "!git clone https://github.com/open-mmlab/mmsegmentation.git \n",
        "%cd mmsegmentation\n",
        "!pip install -e ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mAE_h7XhPT7d",
        "outputId": "f0c976a5-3f21-4dd6-e6c4-584cdd4ff2f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.12.0+cu113 True\n",
            "0.27.0\n"
          ]
        }
      ],
      "source": [
        "# Check Pytorch installation\n",
        "import torch, torchvision\n",
        "print(torch.__version__, torch.cuda.is_available())\n",
        "\n",
        "# Check MMSegmentation installation\n",
        "import mmseg\n",
        "print(mmseg.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUcuC3dUv32I"
      },
      "source": [
        "## Run Inference with MMSeg trained weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H8Fxg8i-wHJE"
      },
      "outputs": [],
      "source": [
        "from mmseg.apis import inference_segmentor, init_segmentor, show_result_pyplot\n",
        "from mmseg.core.evaluation import get_palette\n",
        "# Let's take a look at the dataset\n",
        "import mmcv\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5mNQuc2GsVE"
      },
      "source": [
        "We need to convert the annotation into semantic map format as an image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVlm3zpnyd_y",
        "outputId": "ea7c56a8-27a5-4049-c192-bd1bd7e58c66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WnGZfribFHCx"
      },
      "outputs": [],
      "source": [
        "import os.path as osp\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "# convert dataset annotation to semantic segmentation map\n",
        "data_root = '/content/drive/MyDrive/DiabeticFootUlcerProject/DFUC Dataset/DFUC2022/DFUC2022_train_release'\n",
        "img_dir = 'DFUC2022_train_images'\n",
        "ann_dir = 'DFUC2022_train_masks'\n",
        "# define class and plaette for better visualization\n",
        "classes = ('background','ulcer')\n",
        "palette = [[0, 0, 0], [255, 255, 255]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cr0jSOergEkt"
      },
      "outputs": [],
      "source": [
        "data = '/content/drive/MyDrive/DiabeticFootUlcerProject/DFUC Dataset/DFUC2022/DFUC2022_val_release'\n",
        "ann_dir = '/content/drive/MyDrive/DiabeticFootUlcerProject/DFUC Dataset/DFUC2022/DFUC2022_val_release'\n",
        "for file in mmcv.scandir(ann_dir, suffix='.png'):\n",
        "    seg_map = cv2.imread(osp.join(ann_dir, file),cv2.IMREAD_GRAYSCALE)\n",
        "    seg_map = np.array(seg_map)\n",
        "    seg_map[seg_map != 0] = 255\n",
        "    seg_img = Image.fromarray(seg_map).convert('P')\n",
        "    cv2.imwrite(os.path.join(data, file), seg_map)\n",
        "    seg_img.putpalette(np.array(palette, dtype=np.uint8))\n",
        "    seg_img.save(osp.join(data_root, ann_dir, file.replace('.png', '.png')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9-tjKGQO8vYV"
      },
      "outputs": [],
      "source": [
        "img = Image.open('/content/drive/MyDrive/DiabeticFootUlcerProject/DFUC Dataset/DFUC2022/DFUC2022_val_release/val_deeplab_sub/200137.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79UyGVnE839P",
        "outputId": "52538cd6-b8ef-40e3-dc37-0fc90a17852c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[  0 255]\n"
          ]
        }
      ],
      "source": [
        "print(np.unique(img))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "id": "5MCSS9ABfSks",
        "outputId": "f77dff5b-6abf-4edd-8da7-19768c43e341"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Let's take a look at the segmentation map we got\n",
        "import matplotlib.patches as mpatches\n",
        "img = Image.open('/content/drive/MyDrive/DiabeticFootUlcerProject/DFUC Dataset/DFUC2022/DFUC2022_train_release/DFUC2022_train_masks/101509.png')\n",
        "plt.figure(figsize=(8, 6))\n",
        "im = plt.imshow(np.array(img.convert('RGB')))\n",
        "\n",
        "# create a patch (proxy artist) for every color \n",
        "patches = [mpatches.Patch(color=np.array(palette[i])/255., \n",
        "                          label=classes[i]) for i in range(2)]\n",
        "# put those patched as legend-handles into the legend\n",
        "plt.legend(handles=patches, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., \n",
        "           fontsize='large')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WbeLYCp2k5hl"
      },
      "outputs": [],
      "source": [
        "# split train/val set randomly\n",
        "\n",
        "split_dir = 'splits'\n",
        "mmcv.mkdir_or_exist(osp.join(data_root, split_dir))\n",
        "filename_list = [osp.splitext(filename)[0] for filename in mmcv.scandir(\n",
        "    osp.join(data_root, ann_dir), suffix='.png')]\n",
        "with open(osp.join(data_root, split_dir, 'train.txt'), 'w') as f:\n",
        "  # select first 4/5 as train set\n",
        "  train_length = int(len(filename_list)*0.95)\n",
        "  f.writelines(line + '\\n' for line in filename_list[:train_length])\n",
        "with open(osp.join(data_root, split_dir, 'val.txt'), 'w') as f:\n",
        "  # select last 1/5 as train set\n",
        "  f.writelines(line + '\\n' for line in filename_list[train_length:])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HchvmGYB_rrO"
      },
      "source": [
        "After downloading the data, we need to implement `load_annotations` function in the new dataset class `StanfordBackgroundDataset`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LbsWOw62_o-X"
      },
      "outputs": [],
      "source": [
        "from mmseg.datasets.builder import DATASETS\n",
        "from mmseg.datasets.custom import CustomDataset\n",
        "\n",
        "@DATASETS.register_module()\n",
        "class DFUDataset(CustomDataset):\n",
        "  CLASSES = classes\n",
        "  PALETTE = palette\n",
        "  def __init__(self, split, **kwargs):\n",
        "    super().__init__(img_suffix='.jpg', seg_map_suffix='.png', ignore_index=-100, reduce_zero_label=False, split=split, **kwargs)\n",
        "    assert osp.exists(self.img_dir) and self.split is not None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUVtmn3Iq3WA"
      },
      "source": [
        "### Create a config file\n",
        "In the next step, we need to modify the config for the training. To accelerate the process, we finetune the model from trained weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_gnGaT-vp6lH"
      },
      "outputs": [],
      "source": [
        "!mkdir checkpoints\n",
        "!wget https://download.openmmlab.com/mmsegmentation/v0.5/segformer/segformer_mit-b5_512x512_160k_ade20k/segformer_mit-b5_512x512_160k_ade20k_20210726_145235-94cedf59.pth -P checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wwnj9tRzqX_A"
      },
      "outputs": [],
      "source": [
        "from mmcv import Config\n",
        "cfg = Config.fromfile('configs/segformer/segformer_mit-b5_512x512_160k_ade20k.py')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1y2oV5w97jQo"
      },
      "source": [
        "Since the given config is used to train PSPNet on the cityscapes dataset, we need to modify it accordingly for our new dataset.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyKnYC1Z7iCV",
        "outputId": "9965f5b7-9016-4ec7-cb69-85c8bd9ecf0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Config:\n",
            "norm_cfg = dict(type='BN', requires_grad=True)\n",
            "model = dict(\n",
            "    type='EncoderDecoder',\n",
            "    pretrained=\n",
            "    'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/segformer/mit_b5_20220624-658746d9.pth',\n",
            "    backbone=dict(\n",
            "        type='MixVisionTransformer',\n",
            "        in_channels=3,\n",
            "        embed_dims=64,\n",
            "        num_stages=4,\n",
            "        num_layers=[3, 6, 40, 3],\n",
            "        num_heads=[1, 2, 5, 8],\n",
            "        patch_sizes=[7, 3, 3, 3],\n",
            "        sr_ratios=[8, 4, 2, 1],\n",
            "        out_indices=(0, 1, 2, 3),\n",
            "        mlp_ratio=4,\n",
            "        qkv_bias=True,\n",
            "        drop_rate=0.0,\n",
            "        attn_drop_rate=0.0,\n",
            "        drop_path_rate=0.1,\n",
            "        norm_cfg=dict(type='LN', requires_grad=True)),\n",
            "    decode_head=dict(\n",
            "        type='SegformerHead',\n",
            "        in_channels=[64, 128, 320, 512],\n",
            "        in_index=[0, 1, 2, 3],\n",
            "        channels=256,\n",
            "        dropout_ratio=0.1,\n",
            "        num_classes=2,\n",
            "        norm_cfg=dict(type='BN', requires_grad=True),\n",
            "        align_corners=False,\n",
            "        loss_decode=dict(\n",
            "            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),\n",
            "    train_cfg=dict(),\n",
            "    test_cfg=dict(mode='whole'))\n",
            "dataset_type = 'DFUDataset'\n",
            "data_root = '/content/drive/MyDrive/DiabeticFootUlcerProject/DFUC Dataset/DFUC2022/DFUC2022_train_release'\n",
            "img_norm_cfg = dict(\n",
            "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
            "crop_size = (256, 256)\n",
            "train_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations', reduce_zero_label=False),\n",
            "    dict(type='Resize', img_scale=(480, 480), ratio_range=(0.5, 2.0)),\n",
            "    dict(type='RandomCrop', crop_size=(256, 256), cat_max_ratio=0.75),\n",
            "    dict(type='RandomFlip', flip_ratio=0.5),\n",
            "    dict(type='PhotoMetricDistortion'),\n",
            "    dict(\n",
            "        type='Normalize',\n",
            "        mean=[123.675, 116.28, 103.53],\n",
            "        std=[58.395, 57.12, 57.375],\n",
            "        to_rgb=True),\n",
            "    dict(type='Pad', size=(256, 256), pad_val=0, seg_pad_val=255),\n",
            "    dict(type='DefaultFormatBundle'),\n",
            "    dict(type='Collect', keys=['img', 'gt_semantic_seg'])\n",
            "]\n",
            "test_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(\n",
            "        type='MultiScaleFlipAug',\n",
            "        img_scale=(480, 480),\n",
            "        flip=False,\n",
            "        transforms=[\n",
            "            dict(type='Resize', keep_ratio=True),\n",
            "            dict(type='ResizeToMultiple', size_divisor=32),\n",
            "            dict(type='RandomFlip'),\n",
            "            dict(type='PhotoMetricDistortion'),\n",
            "            dict(\n",
            "                type='Normalize',\n",
            "                mean=[123.675, 116.28, 103.53],\n",
            "                std=[58.395, 57.12, 57.375],\n",
            "                to_rgb=True),\n",
            "            dict(type='ImageToTensor', keys=['img']),\n",
            "            dict(type='Collect', keys=['img'])\n",
            "        ])\n",
            "]\n",
            "data = dict(\n",
            "    samples_per_gpu=16,\n",
            "    workers_per_gpu=16,\n",
            "    train=dict(\n",
            "        type='DFUDataset',\n",
            "        data_root=\n",
            "        '/content/drive/MyDrive/DiabeticFootUlcerProject/DFUC Dataset/DFUC2022/DFUC2022_train_release',\n",
            "        img_dir='DFUC2022_train_images',\n",
            "        ann_dir='DFUC2022_train_masks',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations', reduce_zero_label=False),\n",
            "            dict(type='Resize', img_scale=(480, 480), ratio_range=(0.5, 2.0)),\n",
            "            dict(type='RandomCrop', crop_size=(256, 256), cat_max_ratio=0.75),\n",
            "            dict(type='RandomFlip', flip_ratio=0.5),\n",
            "            dict(type='PhotoMetricDistortion'),\n",
            "            dict(\n",
            "                type='Normalize',\n",
            "                mean=[123.675, 116.28, 103.53],\n",
            "                std=[58.395, 57.12, 57.375],\n",
            "                to_rgb=True),\n",
            "            dict(type='Pad', size=(256, 256), pad_val=0, seg_pad_val=255),\n",
            "            dict(type='DefaultFormatBundle'),\n",
            "            dict(type='Collect', keys=['img', 'gt_semantic_seg'])\n",
            "        ],\n",
            "        split='splits/train.txt'),\n",
            "    val=dict(\n",
            "        type='DFUDataset',\n",
            "        data_root=\n",
            "        '/content/drive/MyDrive/DiabeticFootUlcerProject/DFUC Dataset/DFUC2022/DFUC2022_train_release',\n",
            "        img_dir='DFUC2022_train_images',\n",
            "        ann_dir='DFUC2022_train_masks',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(\n",
            "                type='MultiScaleFlipAug',\n",
            "                img_scale=(480, 480),\n",
            "                flip=False,\n",
            "                transforms=[\n",
            "                    dict(type='Resize', keep_ratio=True),\n",
            "                    dict(type='ResizeToMultiple', size_divisor=32),\n",
            "                    dict(type='RandomFlip'),\n",
            "                    dict(type='PhotoMetricDistortion'),\n",
            "                    dict(\n",
            "                        type='Normalize',\n",
            "                        mean=[123.675, 116.28, 103.53],\n",
            "                        std=[58.395, 57.12, 57.375],\n",
            "                        to_rgb=True),\n",
            "                    dict(type='ImageToTensor', keys=['img']),\n",
            "                    dict(type='Collect', keys=['img'])\n",
            "                ])\n",
            "        ],\n",
            "        split='splits/val.txt'),\n",
            "    test=dict(\n",
            "        type='DFUDataset',\n",
            "        data_root=\n",
            "        '/content/drive/MyDrive/DiabeticFootUlcerProject/DFUC Dataset/DFUC2022/DFUC2022_train_release',\n",
            "        img_dir='DFUC2022_train_images',\n",
            "        ann_dir='DFUC2022_train_masks',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(\n",
            "                type='MultiScaleFlipAug',\n",
            "                img_scale=(480, 480),\n",
            "                flip=False,\n",
            "                transforms=[\n",
            "                    dict(type='Resize', keep_ratio=True),\n",
            "                    dict(type='ResizeToMultiple', size_divisor=32),\n",
            "                    dict(type='RandomFlip'),\n",
            "                    dict(type='PhotoMetricDistortion'),\n",
            "                    dict(\n",
            "                        type='Normalize',\n",
            "                        mean=[123.675, 116.28, 103.53],\n",
            "                        std=[58.395, 57.12, 57.375],\n",
            "                        to_rgb=True),\n",
            "                    dict(type='ImageToTensor', keys=['img']),\n",
            "                    dict(type='Collect', keys=['img'])\n",
            "                ])\n",
            "        ],\n",
            "        split='splits/val.txt'))\n",
            "log_config = dict(\n",
            "    interval=10, hooks=[dict(type='TextLoggerHook', by_epoch=False)])\n",
            "dist_params = dict(backend='nccl')\n",
            "log_level = 'INFO'\n",
            "load_from = '/content/drive/MyDrive/DiabeticFootUlcerProject/DFUC Dataset/DFUC2022/DFUC2022_train_release/best_mIoU_iter_400.pth'\n",
            "resume_from = None\n",
            "workflow = [('train', 1)]\n",
            "cudnn_benchmark = True\n",
            "optimizer = dict(\n",
            "    type='AdamW',\n",
            "    lr=6e-05,\n",
            "    betas=(0.9, 0.999),\n",
            "    weight_decay=0.01,\n",
            "    paramwise_cfg=dict(\n",
            "        custom_keys=dict(\n",
            "            pos_block=dict(decay_mult=0.0),\n",
            "            norm=dict(decay_mult=0.0),\n",
            "            head=dict(lr_mult=10.0))))\n",
            "optimizer_config = dict()\n",
            "lr_config = dict(\n",
            "    policy='poly',\n",
            "    warmup='linear',\n",
            "    warmup_iters=1500,\n",
            "    warmup_ratio=1e-06,\n",
            "    power=1.0,\n",
            "    min_lr=0.0,\n",
            "    by_epoch=False)\n",
            "runner = dict(type='IterBasedRunner', max_iters=35000)\n",
            "checkpoint_config = dict(by_epoch=False, interval=200)\n",
            "evaluation = dict(interval=200, metric='mIoU', pre_eval=True, save_best='mIoU')\n",
            "checkpoint = 'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/segformer/mit_b5_20220624-658746d9.pth'\n",
            "device = 'cuda'\n",
            "work_dir = './work_dirs/tutorial'\n",
            "ignore_index = -100\n",
            "seed = 0\n",
            "gpu_ids = range(0, 1)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from mmseg.apis import set_random_seed\n",
        "\n",
        "# Since we use only one GPU, BN is used instead of SyncBN\n",
        "cfg.norm_cfg = dict(type='BN', requires_grad=True)\n",
        "cfg.model.backbone.norm_cfg = dict(type='LN', requires_grad=True)\n",
        "cfg.model.decode_head.norm_cfg = cfg.norm_cfg\n",
        "#cfg.model.auxiliary_head.norm_cfg = cfg.norm_cfg\n",
        "# modify num classes of the model in decode/auxiliary head\n",
        "cfg.model.decode_head.num_classes = 2\n",
        "#cfg.model.auxiliary_head.num_classes = 2\n",
        "\n",
        "cfg.device = 'cuda'\n",
        "\n",
        "# Modify dataset type and path\n",
        "cfg.dataset_type = 'DFUDataset'\n",
        "cfg.data_root = data_root\n",
        "\n",
        "cfg.data.samples_per_gpu = 16\n",
        "cfg.data.workers_per_gpu= 16\n",
        "\n",
        "cfg.img_norm_cfg = dict(\n",
        "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
        "cfg.crop_size = (256, 256)\n",
        "cfg.train_pipeline = [\n",
        "    dict(type='LoadImageFromFile'),\n",
        "    dict(type='LoadAnnotations',reduce_zero_label=False),\n",
        "    dict(type='Resize', img_scale=(480, 480), ratio_range=(0.5, 2.0)),\n",
        "    dict(type='RandomCrop', crop_size=cfg.crop_size, cat_max_ratio=0.75),\n",
        "    dict(type='RandomFlip', flip_ratio=0.5),\n",
        "    #dict(type=\"RandomRotate\", prob=0.75, degree=180),\n",
        "    dict(type='PhotoMetricDistortion'),\n",
        "    dict(type='Normalize', **cfg.img_norm_cfg),\n",
        "    dict(type='Pad', size=cfg.crop_size, pad_val=0, seg_pad_val=255),\n",
        "    dict(type='DefaultFormatBundle'),\n",
        "    dict(type='Collect', keys=['img', 'gt_semantic_seg']),\n",
        "]\n",
        "\n",
        "cfg.test_pipeline = [\n",
        "    dict(type='LoadImageFromFile'),\n",
        "    dict(\n",
        "        type='MultiScaleFlipAug',\n",
        "        img_scale=(480, 480),\n",
        "        #img_ratios=[0.5, 0.75, 1.0, 1.25, 1.5, 1.75],\n",
        "        flip=False,\n",
        "        transforms=[\n",
        "            dict(type='Resize', keep_ratio=True),\n",
        "            dict(type='ResizeToMultiple', size_divisor=32),\n",
        "            dict(type='RandomFlip'),\n",
        "            #dict(type=\"RandomRotate\", prob=0.75, degree=180),\n",
        "            dict(type=\"PhotoMetricDistortion\"),\n",
        "            dict(type='Normalize', **cfg.img_norm_cfg),\n",
        "            dict(type='ImageToTensor', keys=['img']),\n",
        "            dict(type='Collect', keys=['img']),\n",
        "        ])\n",
        "]\n",
        "\n",
        "\n",
        "cfg.data.train.type = cfg.dataset_type\n",
        "cfg.data.train.data_root = cfg.data_root\n",
        "cfg.data.train.img_dir = img_dir\n",
        "cfg.data.train.ann_dir = ann_dir\n",
        "cfg.data.train.pipeline = cfg.train_pipeline\n",
        "cfg.data.train.split = 'splits/train.txt'\n",
        "\n",
        "cfg.data.val.type = cfg.dataset_type\n",
        "cfg.data.val.data_root = cfg.data_root\n",
        "cfg.data.val.img_dir = img_dir\n",
        "cfg.data.val.ann_dir = ann_dir\n",
        "cfg.data.val.pipeline = cfg.test_pipeline\n",
        "cfg.data.val.split = 'splits/val.txt'\n",
        "\n",
        "cfg.data.test.type = cfg.dataset_type\n",
        "cfg.data.test.data_root = cfg.data_root\n",
        "cfg.data.test.img_dir = img_dir\n",
        "cfg.data.test.ann_dir = ann_dir\n",
        "cfg.data.test.pipeline = cfg.test_pipeline\n",
        "cfg.data.test.split = 'splits/val.txt'\n",
        "\n",
        "# We can still use the pre-trained Mask RCNN model though we do not need to\n",
        "# use the mask branch\n",
        "#cfg.load_from = 'checkpoints/segformer_mit-b5_512x512_160k_ade20k_20210726_145235-94cedf59.pth'\n",
        "cfg.load_from = '/content/drive/MyDrive/DiabeticFootUlcerProject/DFUC Dataset/DFUC2022/DFUC2022_train_release/best_mIoU_iter_400.pth'\n",
        "#cfg.resume_from =  '/content/drive/MyDrive/DiabeticFootUlcerProject/DFUC Dataset/DFUC2022/DFUC2022_train_release/best_mIoU_iter_200.pth'\n",
        "#cfg.resume_from = '/content/mmsegmentation/work_dirs/tutorial/best_mIoU_iter_200.pth'\n",
        "# Set up working dir to save files and logs.\n",
        "cfg.work_dir = './work_dirs/tutorial'\n",
        "\n",
        "cfg.runner.max_iters = 35000\n",
        "cfg.log_config.interval = 10\n",
        "cfg.evaluation.interval = 200\n",
        "cfg.evaluation.save_best = 'mIoU'\n",
        "#cfg.optimizer = dict(type='SGD', lr=0.0001, momentum=0.9, weight_decay=0.0005)\n",
        "#cfg.optimizer = dict( type='Adam', lr=0.0004, weight_decay=0.0001)\n",
        "cfg.checkpoint_config.interval = 200\n",
        "#cfg.lr_config = dict(policy='poly', power=0.9, min_lr=0.001, by_epoch=False)\n",
        "cfg.ignore_index = -100\n",
        "avg_non_ignore = True\n",
        "\n",
        "# Set seed to facitate reproducing the result\n",
        "cfg.seed = 0\n",
        "set_random_seed(0, deterministic=False)\n",
        "cfg.gpu_ids = range(1)\n",
        "\n",
        "# Let's have a look at the final config used for training\n",
        "print(f'Config:\\n{cfg.pretty_text}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWuH14LYF2gQ"
      },
      "source": [
        "### Train and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fcX8Ehko_0SB"
      },
      "outputs": [],
      "source": [
        "from mmseg.datasets import build_dataset\n",
        "from mmseg.models import build_segmentor\n",
        "from mmseg.apis import train_segmentor\n",
        "\n",
        "\n",
        "# Build the dataset\n",
        "datasets = [build_dataset(cfg.data.train)]\n",
        "#cfg.model.init_weights() \n",
        "# Build the detector\n",
        "model = build_segmentor(cfg.model)\n",
        "# Add an attribute for visualization convenience\n",
        "model.CLASSES = datasets[0].CLASSES\n",
        "\n",
        "# Create work_dir\n",
        "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
        "train_segmentor(model, datasets, cfg, distributed=False, validate=True, meta=dict())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bm-KG9OSwBFa"
      },
      "outputs": [],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Kq3PdCMelit"
      },
      "outputs": [],
      "source": [
        "!cp '/content/mmsegmentation/work_dirs/tutorial/best_mIoU_iter_800.pth' '/content/drive/MyDrive/DiabeticFootUlcerProject/DFUC Dataset/DFUC2022/DFUC2022_train_release'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pony4ceMrsTk"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "pickle.dump(model, open('/content/drive/MyDrive/DiabeticFootUlcerProject/DFUC Dataset/DFUC2022/DFUC2022_train_release/segformer_400.pkl', 'wb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HV0jqaPuXUPc"
      },
      "source": [
        "# **Test Image**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q3EgnXjow8bb"
      },
      "outputs": [],
      "source": [
        "image = '/content/drive/MyDrive/DiabeticFootUlcerProject/DFUC Dataset/DFUC2022/DFUC2022_train_release/DFUC2022_train_images/100883.jpg'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g_-iKOCgDf7m"
      },
      "outputs": [],
      "source": [
        "result = inference_segmentor(model, image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42v_FnR-XKyI"
      },
      "source": [
        "# **Re-Ranker**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g5teXj-6wTP3"
      },
      "outputs": [],
      "source": [
        "model.decode_head.sep_bottleneck[1].pointwise_conv.conv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jXLkVVXz06A1"
      },
      "outputs": [],
      "source": [
        "activation = {}\n",
        "def get_activation(name):\n",
        "    def hook(model, input, output):\n",
        "        activation[name].append(output.detach())\n",
        "    return hook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xrgErm510IOn"
      },
      "outputs": [],
      "source": [
        "model.cfg=cfg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E4OE9_XFw_I9"
      },
      "outputs": [],
      "source": [
        "model.decode_head.sep_bottleneck[1].pointwise_conv.conv.register_forward_hook(get_activation(\"init_conv\"))\n",
        "result=inference_segmentor(model, image)\n",
        "feature = activation[\"init_conv\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uYvLeW8Y1ILy"
      },
      "outputs": [],
      "source": [
        "activation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rb_lsMs9oKK1"
      },
      "source": [
        "# **Boost train**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ICNjTG4QoOOh"
      },
      "outputs": [],
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "from datasets import load_metric\n",
        "\n",
        "model.cfg = cfg\n",
        "boost = []\n",
        "metric = load_metric(\"mean_iou\")\n",
        "\n",
        "masks_dir = '/content/drive/MyDrive/DiabeticFootUlcerProject/DFUC Dataset/DFUC2022/DFUC2022_train_release/DFUC2022_train_masks'\n",
        "images_dir = '/content/drive/MyDrive/DiabeticFootUlcerProject/DFUC Dataset/DFUC2022/DFUC2022_train_release/DFUC2022_train_images'\n",
        "output_dir = '/content/drive/MyDrive/DiabeticFootUlcerProject/DFUC Dataset/DFUC2022/DFUC2022_train_release/boost'\n",
        "\n",
        "id2label = {0: 'background', 1: 'Ulcer'}    \n",
        "label2id = {'background': 0, 'Ulcer': 1}\n",
        "\n",
        "\n",
        "text_file = '/content/drive/MyDrive/DiabeticFootUlcerProject/DFUC Dataset/DFUC2022/DFUC2022_train_release/splits/train.txt'\n",
        "with open(text_file) as f:\n",
        "    mylist = f.read().splitlines() \n",
        "\n",
        "Names = sorted(mylist)\n",
        "\n",
        "for fileName in Names:\n",
        "\n",
        "  mask = cv2.imread(os.path.join(masks_dir, fileName +'.png'))\n",
        "  image = cv2.imread(os.path.join(images_dir,fileName + '.jpg'))\n",
        "  img = '/content/drive/MyDrive/DiabeticFootUlcerProject/DFUC Dataset/DFUC2022/DFUC2022_train_release/DFUC2022_train_images/' + fileName + \".jpg\"  \n",
        "  result = inference_segmentor(model, img)\n",
        "  img = mmcv.imread(img)\n",
        "  img = img.copy()\n",
        "  seg = result[0]\n",
        "  seg = mmcv.imresize(seg, img.shape[:2][::-1])\n",
        "  palette = np.array(palette)\n",
        "  assert palette.shape[1] == 3\n",
        "  assert len(palette.shape) == 2\n",
        "  assert 0 < 0.5 <= 1.0\n",
        "  color_seg = np.zeros((seg.shape[0], seg.shape[1], 3), dtype=np.uint8)\n",
        "  for label, color in enumerate(palette):\n",
        "      color_seg[seg == label, :] = color\n",
        "  # convert to BGR\n",
        "  color_seg = color_seg[..., ::-1]\n",
        "\n",
        "  output = color_seg.astype(np.uint8)\n",
        "\n",
        "  mask_cal = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
        "  output_cal = cv2.cvtColor(output, cv2.COLOR_BGR2GRAY)\n",
        "  mask_cal[mask_cal == 255] = 1\n",
        "  output_cal[output_cal == 255] = 1\n",
        "\n",
        "  metric.add(prediction=output_cal, reference=mask_cal)\n",
        "  metrics = metric.compute(num_labels=len(id2label), \n",
        "                              ignore_index=-100,\n",
        "                              reduce_labels=False,\n",
        "    )\n",
        "\n",
        "  if( metrics[\"per_category_iou\"][1] < 0.8):\n",
        "    boost.append(fileName)\n",
        "     # of same height \n",
        "    im_h = cv2.hconcat([mask, image, output])\n",
        "    # show the output image\n",
        "    cv2_imshow(im_h)\n",
        "    print(\"Ulcer_iou:\", metrics[\"per_category_iou\"][1])\n",
        "    print(\"Mean_iou:\", metrics[\"mean_iou\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QP8Uf78M4OCH"
      },
      "source": [
        "# **Predict**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AFmYj3rAB-wo"
      },
      "outputs": [],
      "source": [
        "import cv2, os\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from scipy.ndimage.morphology import binary_fill_holes\n",
        "from skimage.morphology import remove_small_objects\n",
        "from google.colab.patches import cv2_imshow\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "model = pickle.load(open('/content/drive/MyDrive/DiabeticFootUlcerProject/DFUC Dataset/DFUC2022/DFUC2022_train_release/deeplab_0.67388.pkl', 'rb'))"
      ],
      "metadata": {
        "id": "YyJRRUDmapTy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90JevR6FeA1V"
      },
      "source": [
        "Read Filenames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7J4ZVv6eoQGt"
      },
      "outputs": [],
      "source": [
        "text_file = '/content/drive/MyDrive/DiabeticFootUlcerProject/DFUC Dataset/DFUC2022/DFUC2022_test_release/splits/test.txt'\n",
        "with open(text_file) as f:\n",
        "    mylist = f.read().splitlines() \n",
        "\n",
        "mylist = sorted(mylist)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6XhHaneeMGn"
      },
      "source": [
        "Save predicted masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tYkA_5lYPFz_"
      },
      "outputs": [],
      "source": [
        "output_dir = '/content/drive/MyDrive/DiabeticFootUlcerProject/DFUC Dataset/DFUC2022/DFUC2022_test_release/deeplab'\n",
        "\n",
        "mmcv.mkdir_or_exist(output_dir)\n",
        "\n",
        "model.cfg = cfg\n",
        "\n",
        "for imageName in mylist:\n",
        "    img = '/content/drive/MyDrive/DiabeticFootUlcerProject/DFUC Dataset/DFUC2022/DFUC2022_test_release/' + imageName + \".jpg\"  \n",
        "  \n",
        "    result = inference_segmentor(model, img)\n",
        "    img = mmcv.imread(img)\n",
        "    img = img.copy()\n",
        "    seg = result[0]\n",
        "    seg = mmcv.imresize(seg, img.shape[:2][::-1])\n",
        "    palette = np.array(palette)\n",
        "    assert palette.shape[1] == 3\n",
        "    assert len(palette.shape) == 2\n",
        "    assert 0 < 0.5 <= 1.0\n",
        "    color_seg = np.zeros((seg.shape[0], seg.shape[1], 3), dtype=np.uint8)\n",
        "    for label, color in enumerate(palette):\n",
        "        color_seg[seg == label, :] = color\n",
        "    # convert to BGR\n",
        "    color_seg = color_seg[..., ::-1]\n",
        "\n",
        "    img = color_seg.astype(np.uint8)\n",
        "\n",
        "    cv2.imwrite(os.path.join(output_dir, imageName + \".png\"), img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPInVhGHeS3l"
      },
      "source": [
        "Prepare for submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3uROio64LQH7"
      },
      "outputs": [],
      "source": [
        "data = '/content/drive/MyDrive/DiabeticFootUlcerProject/DFUC Dataset/DFUC2022/DFUC2022_test_release/deeplab_sub'\n",
        "ann = '/content/drive/MyDrive/DiabeticFootUlcerProject/DFUC Dataset/DFUC2022/DFUC2022_test_release/deeplab'\n",
        "\n",
        "mmcv.mkdir_or_exist(data)\n",
        "mmcv.mkdir_or_exist(ann)\n",
        "\n",
        "for file in mmcv.scandir(ann, suffix='.png'):\n",
        "    seg_map = cv2.imread(osp.join(ann, file),cv2.IMREAD_GRAYSCALE)\n",
        "    seg_map = np.array(seg_map)\n",
        "    seg_map[seg_map != 0] = 255\n",
        "    #seg_img = Image.fromarray(seg_map).convert('P')\n",
        "    cv2.imwrite(os.path.join(data, file), seg_map)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLm6Bw_OeZ8a"
      },
      "source": [
        "Add dilation to predicted masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qKcmWpRtNj2K"
      },
      "outputs": [],
      "source": [
        "for imageName in mylist:\n",
        "    file = '/content/drive/MyDrive/DiabeticFootUlcerProject/DFUC Dataset/DFUC2022/DFUC2022_val_release/ensemble_post_sub/'+imageName+'.png'\n",
        "    new = '/content/drive/MyDrive/DiabeticFootUlcerProject/DFUC Dataset/DFUC2022/DFUC2022_val_release/ensemble_dilation/'+imageName+'.png'\n",
        "    img = cv2.imread(file,0)\n",
        "    kernel = np.ones((2,2),np.uint8)\n",
        "    dilation = cv2.dilate(img,kernel,iterations = 1)\n",
        "    cv2.imwrite(new, dilation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xc0ACJk_eh1o"
      },
      "source": [
        "Compare masks before and after dilation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OiSuTtf8h6wB"
      },
      "outputs": [],
      "source": [
        "for imageName in mylist:\n",
        "  masks_dir = '/content/drive/MyDrive/DiabeticFootUlcerProject/DFUC Dataset/DFUC2022/DFUC2022_val_release/deeplab'\n",
        "  images_dir = '/content/drive/MyDrive/DiabeticFootUlcerProject/DFUC Dataset/DFUC2022/DFUC2022_val_release'\n",
        "  dilated_dir = '/content/drive/MyDrive/DiabeticFootUlcerProject/DFUC Dataset/DFUC2022/DFUC2022_val_release/deeplab_dilation_sub'\n",
        "\n",
        "  mask = cv2.imread(os.path.join(masks_dir, imageName +'.png'))\n",
        "  image = cv2.imread(os.path.join(images_dir, imageName+ '.jpg'))\n",
        "  dilated = cv2.imread(os.path.join(dilated_dir, imageName +'.png'))\n",
        "\n",
        "  # of same height \n",
        "  im_h = cv2.hconcat([image, mask, dilated])\n",
        "  # show the output image\n",
        "  cv2_imshow(im_h)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uOPBmoPuVgJB"
      },
      "outputs": [],
      "source": [
        "for imageName in mylist:\n",
        "    file = '/content/drive/MyDrive/DiabeticFootUlcerProject/DFUC Dataset/DFUC2022/DFUC2022_val_release/deeplab_sub/'+imageName+'.png'\n",
        "    new = '/content/drive/MyDrive/DiabeticFootUlcerProject/DFUC Dataset/DFUC2022/DFUC2022_val_release/deeplab_erosion/'+imageName+'.png'\n",
        "    img = cv2.imread(file,0)\n",
        "    kernel = np.ones((2,2),np.uint8)\n",
        "    erosion = cv2.erode(img,kernel,iterations = 1)\n",
        "    cv2.imwrite(new, erosion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nWq-_HBlVjoh"
      },
      "outputs": [],
      "source": [
        "for imageName in mylist:\n",
        "\n",
        "  masks_dir = '/content/drive/MyDrive/DiabeticFootUlcerProject/DFUC Dataset/DFUC2022/DFUC2022_val_release/ensemble'\n",
        "  images_dir = '/content/drive/MyDrive/DiabeticFootUlcerProject/DFUC Dataset/DFUC2022/DFUC2022_val_release'\n",
        "  erosion_dir = '/content/drive/MyDrive/DiabeticFootUlcerProject/DFUC Dataset/DFUC2022/DFUC2022_val_release/segformer_erosion'\n",
        "\n",
        "  mask = cv2.imread(os.path.join(masks_dir, imageName +'.png'))\n",
        "  image = cv2.imread(os.path.join(images_dir, imageName+ '.jpg'))\n",
        "  erosion = cv2.imread(os.path.join(erosion_dir, imageName +'.png'))\n",
        "\n",
        "  # of same height \n",
        "  im_h = cv2.hconcat([image, mask, erosion])\n",
        "  # show the output image\n",
        "  cv2_imshow(im_h)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "LR_Gh-NWVq67"
      },
      "outputs": [],
      "source": [
        "for imageName in mylist:\n",
        "\n",
        "  masks_dir = '/content/drive/MyDrive/DiabeticFootUlcerProject/DFUC Dataset/DFUC2022/DFUC2022_val_release/deeplab_sub'\n",
        "  images_dir = '/content/drive/MyDrive/DiabeticFootUlcerProject/DFUC Dataset/DFUC2022/DFUC2022_val_release'\n",
        "  dilated_dir = '/content/drive/MyDrive/DiabeticFootUlcerProject/DFUC Dataset/DFUC2022/DFUC2022_val_release/segformer_sub'\n",
        "\n",
        "  mask = cv2.imread(os.path.join(masks_dir, imageName +'.png'))\n",
        "  image = cv2.imread(os.path.join(images_dir, imageName+ '.jpg'))\n",
        "  dilated = cv2.imread(os.path.join(dilated_dir, imageName +'.png'))\n",
        "\n",
        "  # of same height \n",
        "  im_h = cv2.hconcat([image, mask, dilated])\n",
        "  # show the output image\n",
        "  cv2_imshow(im_h)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBtUUMCQW0gd"
      },
      "source": [
        "# **Get Filename**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b_c5Aw-_yJ9d"
      },
      "outputs": [],
      "source": [
        "# split train/val set randomly\n",
        "data_root = '/content/drive/MyDrive/DiabeticFootUlcerProject/DFUC Dataset/DFUC2022/DFUC2022_test_release'\n",
        "img_dir = 'DFUC2022_test_images'\n",
        "split_dir = 'splits'\n",
        "\n",
        "mmcv.mkdir_or_exist(osp.join(data_root, split_dir))\n",
        "filename_list = [osp.splitext(filename)[0] for filename in mmcv.scandir(\n",
        "    osp.join(data_root), suffix='.jpg')]\n",
        "with open(osp.join(data_root, split_dir, 'test.txt'), 'w') as f:\n",
        "  # select first 4/5 as train set\n",
        "  train_length = int(len(filename_list))\n",
        "  f.writelines(line + '\\n' for line in filename_list[:train_length])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tovN8J9s4SOW"
      },
      "source": [
        "# **Ensemble**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SUUPHHeB__Y8"
      },
      "outputs": [],
      "source": [
        "import cv2, os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "output_dir = '/content/drive/MyDrive/DiabeticFootUlcerProject/DFUC Dataset/DFUC2022/DFUC2022_val_release/new_deeplab'\n",
        "img = mmcv.imread('/content/drive/MyDrive/DiabeticFootUlcerProject/DFUC Dataset/DFUC2022/DFUC2022_val_release/200001.jpg')\n",
        "model1.cfg = cfg\n",
        "model2.cfg = cfg\n",
        "\n",
        "result1 = inference_segmentor(model1, img)\n",
        "img1 = mmcv.imread(img)\n",
        "img1 = img1.copy()\n",
        "seg = result1[0]\n",
        "seg = mmcv.imresize(seg, img1.shape[:2][::-1])\n",
        "palette = np.array(palette)\n",
        "assert palette.shape[1] == 3\n",
        "assert len(palette.shape) == 2\n",
        "assert 0 < 0.5 <= 1.0\n",
        "color_seg = np.zeros((seg.shape[0], seg.shape[1], 3), dtype=np.uint8)\n",
        "for label, color in enumerate(palette):\n",
        "    color_seg[seg == label, :] = color\n",
        "# convert to BGR\n",
        "color_seg = color_seg[..., ::-1]\n",
        "\n",
        "img1 = color_seg.astype(np.uint8)\n",
        "\n",
        "result2 = inference_segmentor(model2, img)\n",
        "img2 = mmcv.imread(img)\n",
        "img2 = img2.copy()\n",
        "seg = result2[0]\n",
        "seg = mmcv.imresize(seg, img2.shape[:2][::-1])\n",
        "palette = np.array(palette)\n",
        "assert palette.shape[1] == 3\n",
        "assert len(palette.shape) == 2\n",
        "assert 0 < 0.5 <= 1.0\n",
        "color_seg = np.zeros((seg.shape[0], seg.shape[1], 3), dtype=np.uint8)\n",
        "for label, color in enumerate(palette):\n",
        "    color_seg[seg == label, :] = color\n",
        "# convert to BGR\n",
        "color_seg = color_seg[..., ::-1]\n",
        "\n",
        "img2 = color_seg.astype(np.uint8)\n",
        "\n",
        "res = np.array((img1+img2)/2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ECwVNhYUxnlE"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "model1 = pickle.load(open('/content/drive/MyDrive/DiabeticFootUlcerProject/DFUC Dataset/DFUC2022/DFUC2022_train_release/deeplab_R101_75.pkl', 'rb'))\n",
        "model2 = pickle.load(open('/content/drive/MyDrive/DiabeticFootUlcerProject/DFUC Dataset/DFUC2022/DFUC2022_train_release/deeplab_74.88.pkl', 'rb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ekG__UfaH_OU"
      },
      "outputs": [],
      "source": [
        "import cv2, os\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from scipy.ndimage.morphology import binary_fill_holes\n",
        "from skimage.morphology import remove_small_objects\n",
        "output_dir = '/content/drive/MyDrive/DiabeticFootUlcerProject/DFUC Dataset/DFUC2022/DFUC2022_val_release/new_deeplab'\n",
        "#img = mmcv.imread('/content/drive/MyDrive/DiabeticFootUlcerProject/DFUC Dataset/DFUC2022/DFUC2022_val_release/DFUC2022_val_images/100860.jpg')\n",
        "\n",
        "model1.cfg = cfg\n",
        "model2.cfg = cfg\n",
        "\n",
        "\n",
        "for imageName in mylist:\n",
        "    img = '/content/drive/MyDrive/DiabeticFootUlcerProject/DFUC Dataset/DFUC2022/DFUC2022_val_release/' + imageName + \".jpg\"  \n",
        "  \n",
        "    result1 = inference_segmentor(model1, img)\n",
        "    img1 = mmcv.imread(img)\n",
        "    img1 = img1.copy()\n",
        "    seg = result1[0]\n",
        "    seg = mmcv.imresize(seg, img1.shape[:2][::-1])\n",
        "    palette = np.array(palette)\n",
        "    assert palette.shape[1] == 3\n",
        "    assert len(palette.shape) == 2\n",
        "    assert 0 < 0.5 <= 1.0\n",
        "    color_seg = np.zeros((seg.shape[0], seg.shape[1], 3), dtype=np.uint8)\n",
        "    for label, color in enumerate(palette):\n",
        "        color_seg[seg == label, :] = color\n",
        "    # convert to BGR\n",
        "    color_seg = color_seg[..., ::-1]\n",
        "\n",
        "    img1 = color_seg.astype(np.uint8)\n",
        "\n",
        "    result2 = inference_segmentor(model2, img)\n",
        "    img2 = mmcv.imread(img)\n",
        "    img2 = img2.copy()\n",
        "    seg = result2[0]\n",
        "    seg = mmcv.imresize(seg, img2.shape[:2][::-1])\n",
        "    palette = np.array(palette)\n",
        "    assert palette.shape[1] == 3\n",
        "    assert len(palette.shape) == 2\n",
        "    assert 0 < 0.5 <= 1.0\n",
        "    color_seg = np.zeros((seg.shape[0], seg.shape[1], 3), dtype=np.uint8)\n",
        "    for label, color in enumerate(palette):\n",
        "        color_seg[seg == label, :] = color\n",
        "    # convert to BGR\n",
        "    color_seg = color_seg[..., ::-1]\n",
        "\n",
        "    img2 = color_seg.astype(np.uint8)\n",
        "\n",
        "    res = np.array((img1+img2)/2)\n",
        "\n",
        "    cv2.imwrite(os.path.join(output_dir, imageName + \".png\"), res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TbfEYneSHE_y"
      },
      "outputs": [],
      "source": [
        "import cv2, os\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from scipy.ndimage.morphology import binary_fill_holes\n",
        "from skimage.morphology import remove_small_objects\n",
        "output_dir = '/content/drive/MyDrive/DiabeticFootUlcerProject/DFUC Dataset/DFUC2022/DFUC2022_val_release/ensemble'\n",
        "#img = mmcv.imread('/content/drive/MyDrive/DiabeticFootUlcerProject/DFUC Dataset/DFUC2022/DFUC2022_val_release/DFUC2022_val_images/100860.jpg')\n",
        "\n",
        "\n",
        "for imageName in mylist:\n",
        "    img1 = '/content/drive/MyDrive/DiabeticFootUlcerProject/DFUC Dataset/DFUC2022/DFUC2022_val_release/segformer_sub/' + imageName + \".png\"  \n",
        "    img1 = mmcv.imread(img1)\n",
        "    img2 = '/content/drive/MyDrive/DiabeticFootUlcerProject/DFUC Dataset/DFUC2022/DFUC2022_val_release/deeplab_sub/' + imageName + \".png\"  \n",
        "    img2 = mmcv.imread(img2)\n",
        "    res = (img1+img2)/2\n",
        "    cv2.imwrite(os.path.join(output_dir, imageName + \".png\"), res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gNS5gumc6BvU"
      },
      "outputs": [],
      "source": [
        "import cv2, os\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from scipy.ndimage.morphology import binary_fill_holes\n",
        "from skimage.morphology import remove_small_objects\n",
        "from skimage.io import imsave, imread\n",
        "\n",
        "output_dir = '/content/drive/MyDrive/DiabeticFootUlcerProject/DFUC Dataset/DFUC2022/DFUC2022_val_release/ensemble_post'\n",
        "#img = mmcv.imread('/content/drive/MyDrive/DiabeticFootUlcerProject/DFUC Dataset/DFUC2022/DFUC2022_val_release/DFUC2022_val_images/100860.jpg')\n",
        "\n",
        "for imageName in mylist:\n",
        "    res = '/content/drive/MyDrive/DiabeticFootUlcerProject/DFUC Dataset/DFUC2022/DFUC2022_val_release/ensemble_sub/' + imageName + \".png\"  \n",
        "    res = cv2.imread(res,cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    stage1_mask_ep = np.uint(res>0.5)\n",
        "\n",
        "    img_rmv_small = stage1_mask_ep\n",
        "    img_rmv_small = binary_fill_holes(img_rmv_small > 0).astype(float)\n",
        "    img_rmv_small = remove_small_objects(img_rmv_small>0.5, min_size=int(100), connectivity=2)\n",
        "    img_rmv_small = img_rmv_small.astype(np.uint8)*255\n",
        "    #plt.imshow(img_rmv_small)\n",
        "    cv2.imwrite(os.path.join(output_dir, imageName + \".png\"), (img_rmv_small))\n",
        "    #plt.savefig(output_dir+ 'figure/{}.png'.format(get_id_from_file_path(test_files[i], opts['imageType_test'])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "obvJHGwXD5kR"
      },
      "outputs": [],
      "source": [
        "img = mmcv.imread('/content/drive/MyDrive/DiabeticFootUlcerProject/DFUC Dataset/DFUC2022/DFUC2022_val_release/ensemble_post/200001.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6T-0LsdEH0v",
        "outputId": "59a214f9-4fbb-4e17-e92c-ba07c38d10cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[  0 255]\n"
          ]
        }
      ],
      "source": [
        "print(np.unique(img))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGJs510z4ZhE"
      },
      "source": [
        "# **Plot Images**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ImxNppByqids"
      },
      "outputs": [],
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "from datasets import load_metric\n",
        "\n",
        "metric = load_metric(\"mean_iou\")\n",
        "\n",
        "masks_dir = '/content/drive/MyDrive/DiabeticFootUlcerProject/DFUC Dataset/DFUC2022/DFUC2022_train_release/DFUC2022_train_masks'\n",
        "images_dir = '/content/drive/MyDrive/DiabeticFootUlcerProject/DFUC Dataset/DFUC2022/DFUC2022_train_release/DFUC2022_train_images'\n",
        "output_dir = '/content/drive/MyDrive/DiabeticFootUlcerProject/DFUC Dataset/DFUC2022/DFUC2022_train_release/DeepLab_Output'\n",
        "\n",
        "id2label = {0: 'background', 1: 'Ulcer'}    \n",
        "label2id = {'background': 0, 'Ulcer': 1}\n",
        "\n",
        "Names = sorted(os.listdir(output_dir))\n",
        "\n",
        "for fileName in Names:\n",
        "\n",
        "  mask = cv2.imread(os.path.join(masks_dir, str(fileName[:-4]) +'.png'))\n",
        "  image = cv2.imread(os.path.join(images_dir, str(fileName[:-4] + '.jpg')))\n",
        "  output = cv2.imread(os.path.join(output_dir, str(fileName[:-4]) +'.png'))\n",
        "\n",
        "  # of same height \n",
        "  im_h = cv2.hconcat([mask, image, output])\n",
        "  # show the output image\n",
        "  cv2_imshow(im_h)\n",
        "  '''\n",
        "  mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
        "  output = cv2.cvtColor(output, cv2.COLOR_BGR2GRAY)\n",
        "  mask[mask == 255] = 1\n",
        "  output[output == 255] = 1\n",
        "\n",
        "  metric.add(prediction=output, reference=mask)\n",
        "  metrics = metric.compute(num_labels=len(id2label), \n",
        "                              ignore_index=-100,\n",
        "                              reduce_labels=False,\n",
        "    )\n",
        "\n",
        "  print(\"Ulcer_iou:\", metrics[\"per_category_iou\"][1])\n",
        "  print(\"Mean_iou:\", metrics[\"mean_iou\"])\n",
        "  '''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odc7JlCE4eYq"
      },
      "source": [
        "# **SETR Configs**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZbxcTJrW9j62"
      },
      "outputs": [],
      "source": [
        "#### --------------- cfg for setr mla -------------- ####\n",
        "\n",
        "from mmseg.apis import set_random_seed\n",
        "\n",
        "# Since we use only one GPU, BN is used instead of SyncBN\n",
        "cfg.norm_cfg = dict(type='BN', requires_grad=True)\n",
        "cfg.model.backbone.norm_cfg = dict(type='LN', requires_grad=True)\n",
        "cfg.model.decode_head.norm_cfg = cfg.norm_cfg\n",
        "#cfg.model.auxiliary_head.norm_cfg = cfg.norm_cfg\n",
        "# modify num classes of the model in decode/auxiliary head\n",
        "cfg.model.decode_head.num_classes = 2\n",
        "#cfg.model.auxiliary_head.num_classes = 2\n",
        "cfg.model.neck=[dict(\n",
        "        type='MLANeck',\n",
        "        in_channels=[1024, 1024, 1024, 1024],\n",
        "        out_channels=256,\n",
        "        norm_cfg=dict(type='BN', requires_grad=True),\n",
        "        act_cfg=dict(type='ReLU'))]\n",
        "\n",
        "cfg.model.auxiliary_head = [\n",
        "        dict(\n",
        "            type='FCNHead',\n",
        "            in_channels=256,\n",
        "            channels=256,\n",
        "            in_index=0,\n",
        "            dropout_ratio=0,\n",
        "            norm_cfg=dict(type='BN', requires_grad=True),\n",
        "            act_cfg=dict(type='ReLU'),\n",
        "            num_convs=0,\n",
        "            kernel_size=1,\n",
        "            concat_input=False,\n",
        "            num_classes=2,\n",
        "            align_corners=False,\n",
        "            loss_decode=dict(\n",
        "                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=0.4)),\n",
        "        dict(\n",
        "            type='FCNHead',\n",
        "            in_channels=256,\n",
        "            channels=256,\n",
        "            in_index=1,\n",
        "            dropout_ratio=0,\n",
        "            norm_cfg=dict(type='BN', requires_grad=True),\n",
        "            act_cfg=dict(type='ReLU'),\n",
        "            num_convs=0,\n",
        "            kernel_size=1,\n",
        "            concat_input=False,\n",
        "            num_classes=2,\n",
        "            align_corners=False,\n",
        "            loss_decode=dict(\n",
        "                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=0.4)),\n",
        "        dict(\n",
        "            type='FCNHead',\n",
        "            in_channels=256,\n",
        "            channels=256,\n",
        "            in_index=2,\n",
        "            dropout_ratio=0,\n",
        "            norm_cfg=dict(type='BN', requires_grad=True),\n",
        "            act_cfg=dict(type='ReLU'),\n",
        "            num_convs=0,\n",
        "            kernel_size=1,\n",
        "            concat_input=False,\n",
        "            num_classes=2,\n",
        "            align_corners=False,\n",
        "            loss_decode=dict(\n",
        "                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=0.4)),\n",
        "        dict(\n",
        "            type='FCNHead',\n",
        "            in_channels=256,\n",
        "            channels=256,\n",
        "            in_index=3,\n",
        "            dropout_ratio=0,\n",
        "            norm_cfg=dict(type='BN', requires_grad=True),\n",
        "            act_cfg=dict(type='ReLU'),\n",
        "            num_convs=0,\n",
        "            kernel_size=1,\n",
        "            concat_input=False,\n",
        "            num_classes=2,\n",
        "            align_corners=False,\n",
        "            loss_decode=dict(\n",
        "                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=0.4))\n",
        "    ]\n",
        "\n",
        "# Modify dataset type and path\n",
        "cfg.dataset_type = 'DFUDataset'\n",
        "cfg.data_root = data_root\n",
        "\n",
        "cfg.data.samples_per_gpu = 16\n",
        "cfg.data.workers_per_gpu= 16\n",
        "\n",
        "cfg.img_norm_cfg = dict(\n",
        "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
        "cfg.crop_size = (256, 256)\n",
        "cfg.train_pipeline = [\n",
        "    dict(type='LoadImageFromFile'),\n",
        "    dict(type='LoadAnnotations',reduce_zero_label=False),\n",
        "    dict(type='Resize', img_scale=(320, 240), ratio_range=(0.5, 2.0)),\n",
        "    dict(type='RandomCrop', crop_size=cfg.crop_size, cat_max_ratio=0.75),\n",
        "    dict(type='RandomFlip', flip_ratio=0.5),\n",
        "    dict(type='PhotoMetricDistortion'),\n",
        "    dict(type='Normalize', **cfg.img_norm_cfg),\n",
        "    dict(type='Pad', size=cfg.crop_size, pad_val=0, seg_pad_val=255),\n",
        "    dict(type='DefaultFormatBundle'),\n",
        "    dict(type='Collect', keys=['img', 'gt_semantic_seg']),\n",
        "]\n",
        "\n",
        "cfg.test_pipeline = [\n",
        "    dict(type='LoadImageFromFile'),\n",
        "    dict(\n",
        "        type='MultiScaleFlipAug',\n",
        "        img_scale=(320, 240),\n",
        "        img_ratios=[0.5, 0.75, 1.0, 1.25, 1.5, 1.75],\n",
        "        flip=False,\n",
        "        transforms=[\n",
        "            dict(type='Resize', keep_ratio=True),\n",
        "            dict(type='ResizeToMultiple', size_divisor=32),\n",
        "            dict(type='RandomFlip'),\n",
        "            dict(type='Normalize', **cfg.img_norm_cfg),\n",
        "            dict(type='ImageToTensor', keys=['img']),\n",
        "            dict(type='Collect', keys=['img']),\n",
        "        ])\n",
        "]\n",
        "\n",
        "\n",
        "cfg.data.train.type = cfg.dataset_type\n",
        "cfg.data.train.data_root = cfg.data_root\n",
        "cfg.data.train.img_dir = img_dir\n",
        "cfg.data.train.ann_dir = ann_dir\n",
        "cfg.data.train.pipeline = cfg.train_pipeline\n",
        "cfg.data.train.split = 'splits/train.txt'\n",
        "\n",
        "cfg.data.val.type = cfg.dataset_type\n",
        "cfg.data.val.data_root = cfg.data_root\n",
        "cfg.data.val.img_dir = img_dir\n",
        "cfg.data.val.ann_dir = ann_dir\n",
        "cfg.data.val.pipeline = cfg.test_pipeline\n",
        "cfg.data.val.split = 'splits/val.txt'\n",
        "\n",
        "cfg.data.test.type = cfg.dataset_type\n",
        "cfg.data.test.data_root = cfg.data_root\n",
        "cfg.data.test.img_dir = img_dir\n",
        "cfg.data.test.ann_dir = ann_dir\n",
        "cfg.data.test.pipeline = cfg.test_pipeline\n",
        "cfg.data.test.split = 'splits/val.txt'\n",
        "\n",
        "# We can still use the pre-trained Mask RCNN model though we do not need to\n",
        "# use the mask branch\n",
        "cfg.load_from = 'checkpoints/setr_mla_vit-large_8x1_768x768_80k_cityscapes_20211119_101003-7f8dccbe.pth'\n",
        "# Set up working dir to save files and logs.\n",
        "cfg.work_dir = './work_dirs/tutorial'\n",
        "\n",
        "cfg.runner.max_iters = 10000\n",
        "cfg.log_config.interval = 10\n",
        "cfg.evaluation.interval = 200\n",
        "cfg.evaluation.save_best = 'mIoU'\n",
        "\n",
        "\n",
        "cfg.checkpoint_config.interval = 200\n",
        "cfg.lr_config = dict(policy='poly', power=0.9, min_lr=0.001, by_epoch=False)\n",
        "cfg.ignore_index = -100\n",
        "avg_non_ignore = True\n",
        "\n",
        "\n",
        "# Set seed to facitate reproducing the result\n",
        "cfg.seed = 0\n",
        "set_random_seed(0, deterministic=False)\n",
        "cfg.gpu_ids = range(1)\n",
        "\n",
        "# Let's have a look at the final config used for training\n",
        "print(f'Config:\\n{cfg.pretty_text}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9NLL_kO_7X-z"
      },
      "outputs": [],
      "source": [
        "#### --------------- cfg for setr pup -------------- ####\n",
        "\n",
        "from mmseg.apis import set_random_seed\n",
        "\n",
        "# Since we use only one GPU, BN is used instead of SyncBN\n",
        "cfg.norm_cfg = dict(type='BN', requires_grad=True)\n",
        "cfg.model.backbone.norm_cfg = dict(type='LN', requires_grad=True)\n",
        "cfg.model.decode_head.norm_cfg = cfg.norm_cfg\n",
        "#cfg.model.auxiliary_head.norm_cfg = cfg.norm_cfg\n",
        "# modify num classes of the model in decode/auxiliary head\n",
        "cfg.model.decode_head.num_classes = 2\n",
        "#cfg.model.auxiliary_head.num_classes = 2\n",
        "\n",
        "cfg.model.auxiliary_head = [\n",
        "        dict(\n",
        "            type='SETRUPHead',\n",
        "            in_channels=1024,\n",
        "            channels=256,\n",
        "            in_index=0,\n",
        "            num_classes=2,\n",
        "            dropout_ratio=0,\n",
        "            norm_cfg=cfg.norm_cfg,\n",
        "            num_convs=1,\n",
        "            up_scale=4,\n",
        "            kernel_size=3,\n",
        "            align_corners=False,\n",
        "            loss_decode=dict(\n",
        "                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=0.4)),\n",
        "        dict(\n",
        "            type='SETRUPHead',\n",
        "            in_channels=1024,\n",
        "            channels=256,\n",
        "            in_index=1,\n",
        "            num_classes=2,\n",
        "            dropout_ratio=0,\n",
        "            norm_cfg=cfg.norm_cfg,\n",
        "            num_convs=1,\n",
        "            up_scale=4,\n",
        "            kernel_size=3,\n",
        "            align_corners=False,\n",
        "            loss_decode=dict(\n",
        "                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=0.4)),\n",
        "        dict(\n",
        "            type='SETRUPHead',\n",
        "            in_channels=1024,\n",
        "            channels=256,\n",
        "            in_index=2,\n",
        "            num_classes=2,\n",
        "            dropout_ratio=0,\n",
        "            norm_cfg=cfg.norm_cfg,\n",
        "            num_convs=1,\n",
        "            up_scale=4,\n",
        "            kernel_size=3,\n",
        "            align_corners=False,\n",
        "            loss_decode=dict(\n",
        "                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=0.4)),\n",
        "    ]\n",
        "\n",
        "# Modify dataset type and path\n",
        "cfg.dataset_type = 'DFUDataset'\n",
        "cfg.data_root = data_root\n",
        "\n",
        "cfg.data.samples_per_gpu = 16\n",
        "cfg.data.workers_per_gpu= 16\n",
        "\n",
        "cfg.img_norm_cfg = dict(\n",
        "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
        "cfg.crop_size = (256, 256)\n",
        "cfg.train_pipeline = [\n",
        "    dict(type='LoadImageFromFile'),\n",
        "    dict(type='LoadAnnotations',reduce_zero_label=False),\n",
        "    dict(type='Resize', img_scale=(320, 240), ratio_range=(0.5, 2.0)),\n",
        "    dict(type='RandomCrop', crop_size=cfg.crop_size, cat_max_ratio=0.75),\n",
        "    dict(type='RandomFlip', flip_ratio=0.5),\n",
        "    dict(type='PhotoMetricDistortion'),\n",
        "    dict(type='Normalize', **cfg.img_norm_cfg),\n",
        "    dict(type='Pad', size=cfg.crop_size, pad_val=0, seg_pad_val=255),\n",
        "    dict(type='DefaultFormatBundle'),\n",
        "    dict(type='Collect', keys=['img', 'gt_semantic_seg']),\n",
        "]\n",
        "\n",
        "cfg.test_pipeline = [\n",
        "    dict(type='LoadImageFromFile'),\n",
        "    dict(\n",
        "        type='MultiScaleFlipAug',\n",
        "        img_scale=(320, 240),\n",
        "        img_ratios=[0.5, 0.75, 1.0, 1.25, 1.5, 1.75],\n",
        "        flip=False,\n",
        "        transforms=[\n",
        "            dict(type='Resize', keep_ratio=True),\n",
        "            dict(type='ResizeToMultiple', size_divisor=32),\n",
        "            dict(type='RandomFlip'),\n",
        "            dict(type='Normalize', **cfg.img_norm_cfg),\n",
        "            dict(type='ImageToTensor', keys=['img']),\n",
        "            dict(type='Collect', keys=['img']),\n",
        "        ])\n",
        "]\n",
        "\n",
        "\n",
        "cfg.data.train.type = cfg.dataset_type\n",
        "cfg.data.train.data_root = cfg.data_root\n",
        "cfg.data.train.img_dir = img_dir\n",
        "cfg.data.train.ann_dir = ann_dir\n",
        "cfg.data.train.pipeline = cfg.train_pipeline\n",
        "cfg.data.train.split = 'splits/train.txt'\n",
        "\n",
        "cfg.data.val.type = cfg.dataset_type\n",
        "cfg.data.val.data_root = cfg.data_root\n",
        "cfg.data.val.img_dir = img_dir\n",
        "cfg.data.val.ann_dir = ann_dir\n",
        "cfg.data.val.pipeline = cfg.test_pipeline\n",
        "cfg.data.val.split = 'splits/val.txt'\n",
        "\n",
        "cfg.data.test.type = cfg.dataset_type\n",
        "cfg.data.test.data_root = cfg.data_root\n",
        "cfg.data.test.img_dir = img_dir\n",
        "cfg.data.test.ann_dir = ann_dir\n",
        "cfg.data.test.pipeline = cfg.test_pipeline\n",
        "cfg.data.test.split = 'splits/val.txt'\n",
        "\n",
        "# We can still use the pre-trained Mask RCNN model though we do not need to\n",
        "# use the mask branch\n",
        "cfg.load_from = 'checkpoints/setr_pup_512x512_160k_b16_ade20k_20210619_191343-7e0ce826.pth'\n",
        "# Set up working dir to save files and logs.\n",
        "cfg.work_dir = './work_dirs/tutorial'\n",
        "\n",
        "cfg.runner.max_iters = 10000\n",
        "cfg.log_config.interval = 10\n",
        "cfg.evaluation.interval = 200\n",
        "cfg.evaluation.save_best = 'mIoU'\n",
        "\n",
        "\n",
        "cfg.checkpoint_config.interval = 200\n",
        "cfg.lr_config = dict(policy='poly', power=0.9, min_lr=0.001, by_epoch=False)\n",
        "cfg.ignore_index = -100\n",
        "avg_non_ignore = True\n",
        "\n",
        "\n",
        "# Set seed to facitate reproducing the result\n",
        "cfg.seed = 0\n",
        "set_random_seed(0, deterministic=False)\n",
        "cfg.gpu_ids = range(1)\n",
        "\n",
        "# Let's have a look at the final config used for training\n",
        "print(f'Config:\\n{cfg.pretty_text}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tSLLmE497xL9"
      },
      "outputs": [],
      "source": [
        "#### --------------- cfg for setr naive -------------- ####\n",
        "\n",
        "from mmseg.apis import set_random_seed\n",
        "\n",
        "# Since we use only one GPU, BN is used instead of SyncBN\n",
        "cfg.norm_cfg = dict(type='BN', requires_grad=True)\n",
        "cfg.model.backbone.norm_cfg = dict(type='LN', requires_grad=True)\n",
        "cfg.model.decode_head.norm_cfg = cfg.norm_cfg\n",
        "#cfg.model.auxiliary_head.norm_cfg = cfg.norm_cfg\n",
        "# modify num classes of the model in decode/auxiliary head\n",
        "cfg.model.decode_head.num_classes = 2\n",
        "#cfg.model.auxiliary_head.num_classes = 2\n",
        "\n",
        "cfg.model.auxiliary_head = [\n",
        "        dict(\n",
        "            type='SETRUPHead',\n",
        "            in_channels=1024,\n",
        "            channels=256,\n",
        "            in_index=0,\n",
        "            num_classes=2,\n",
        "            dropout_ratio=0,\n",
        "            norm_cfg=cfg.norm_cfg,\n",
        "            num_convs=1,\n",
        "            up_scale=4,\n",
        "            kernel_size=1,\n",
        "            align_corners=False,\n",
        "            loss_decode=dict(\n",
        "                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=0.4)),\n",
        "        dict(\n",
        "            type='SETRUPHead',\n",
        "            in_channels=1024,\n",
        "            channels=256,\n",
        "            in_index=1,\n",
        "            num_classes=2,\n",
        "            dropout_ratio=0,\n",
        "            norm_cfg=cfg.norm_cfg,\n",
        "            num_convs=1,\n",
        "            up_scale=4,\n",
        "            kernel_size=1,\n",
        "            align_corners=False,\n",
        "            loss_decode=dict(\n",
        "                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=0.4)),\n",
        "        dict(\n",
        "            type='SETRUPHead',\n",
        "            in_channels=1024,\n",
        "            channels=256,\n",
        "            in_index=2,\n",
        "            num_classes=2,\n",
        "            dropout_ratio=0,\n",
        "            norm_cfg=cfg.norm_cfg,\n",
        "            num_convs=1,\n",
        "            up_scale=4,\n",
        "            kernel_size=1,\n",
        "            align_corners=False,\n",
        "            loss_decode=dict(\n",
        "                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=0.4))\n",
        "    ]\n",
        "\n",
        "# Modify dataset type and path\n",
        "cfg.dataset_type = 'DFUDataset'\n",
        "cfg.data_root = data_root\n",
        "\n",
        "cfg.data.samples_per_gpu = 16\n",
        "cfg.data.workers_per_gpu= 16\n",
        "\n",
        "cfg.img_norm_cfg = dict(\n",
        "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
        "cfg.crop_size = (256, 256)\n",
        "cfg.train_pipeline = [\n",
        "    dict(type='LoadImageFromFile'),\n",
        "    dict(type='LoadAnnotations',reduce_zero_label=False),\n",
        "    dict(type='Resize', img_scale=(320, 240), ratio_range=(0.5, 2.0)),\n",
        "    dict(type='RandomCrop', crop_size=cfg.crop_size, cat_max_ratio=0.75),\n",
        "    dict(type='RandomFlip', flip_ratio=0.5),\n",
        "    dict(type='PhotoMetricDistortion'),\n",
        "    dict(type='Normalize', **cfg.img_norm_cfg),\n",
        "    dict(type='Pad', size=cfg.crop_size, pad_val=0, seg_pad_val=255),\n",
        "    dict(type='DefaultFormatBundle'),\n",
        "    dict(type='Collect', keys=['img', 'gt_semantic_seg']),\n",
        "]\n",
        "\n",
        "cfg.test_pipeline = [\n",
        "    dict(type='LoadImageFromFile'),\n",
        "    dict(\n",
        "        type='MultiScaleFlipAug',\n",
        "        img_scale=(320, 240),\n",
        "        img_ratios=[0.5, 0.75, 1.0, 1.25, 1.5, 1.75],\n",
        "        flip=False,\n",
        "        transforms=[\n",
        "            dict(type='Resize', keep_ratio=True),\n",
        "            dict(type='ResizeToMultiple', size_divisor=32),\n",
        "            dict(type='RandomFlip'),\n",
        "            dict(type='Normalize', **cfg.img_norm_cfg),\n",
        "            dict(type='ImageToTensor', keys=['img']),\n",
        "            dict(type='Collect', keys=['img']),\n",
        "        ])\n",
        "]\n",
        "\n",
        "\n",
        "cfg.data.train.type = cfg.dataset_type\n",
        "cfg.data.train.data_root = cfg.data_root\n",
        "cfg.data.train.img_dir = img_dir\n",
        "cfg.data.train.ann_dir = ann_dir\n",
        "cfg.data.train.pipeline = cfg.train_pipeline\n",
        "cfg.data.train.split = 'splits/train.txt'\n",
        "\n",
        "cfg.data.val.type = cfg.dataset_type\n",
        "cfg.data.val.data_root = cfg.data_root\n",
        "cfg.data.val.img_dir = img_dir\n",
        "cfg.data.val.ann_dir = ann_dir\n",
        "cfg.data.val.pipeline = cfg.test_pipeline\n",
        "cfg.data.val.split = 'splits/val.txt'\n",
        "\n",
        "cfg.data.test.type = cfg.dataset_type\n",
        "cfg.data.test.data_root = cfg.data_root\n",
        "cfg.data.test.img_dir = img_dir\n",
        "cfg.data.test.ann_dir = ann_dir\n",
        "cfg.data.test.pipeline = cfg.test_pipeline\n",
        "cfg.data.test.split = 'splits/val.txt'\n",
        "\n",
        "# We can still use the pre-trained Mask RCNN model though we do not need to\n",
        "# use the mask branch\n",
        "cfg.load_from = 'checkpoints/setr_naive_512x512_160k_b16_ade20k_20210619_191258-061f24f5.pth'\n",
        "# Set up working dir to save files and logs.\n",
        "cfg.work_dir = './work_dirs/tutorial'\n",
        "\n",
        "cfg.runner.max_iters = 10000\n",
        "cfg.log_config.interval = 10\n",
        "cfg.evaluation.interval = 200\n",
        "cfg.evaluation.save_best = 'mIoU'\n",
        "\n",
        "\n",
        "cfg.checkpoint_config.interval = 200\n",
        "cfg.lr_config = dict(policy='poly', power=0.9, min_lr=0.001, by_epoch=False)\n",
        "cfg.ignore_index = -100\n",
        "avg_non_ignore = True\n",
        "\n",
        "\n",
        "# Set seed to facitate reproducing the result\n",
        "cfg.seed = 0\n",
        "set_random_seed(0, deterministic=False)\n",
        "cfg.gpu_ids = range(1)\n",
        "\n",
        "# Let's have a look at the final config used for training\n",
        "print(f'Config:\\n{cfg.pretty_text}')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "HV0jqaPuXUPc",
        "42v_FnR-XKyI",
        "rb_lsMs9oKK1",
        "fBtUUMCQW0gd",
        "oGJs510z4ZhE",
        "odc7JlCE4eYq"
      ],
      "name": "MMSegmentation.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}